{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d1b8a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob,os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b750de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_expression_data(direction):\n",
    "    \"\"\"\n",
    "    This function read in all .JSON files along the given direction. \n",
    "    Involved conditions, expression data under each condition,\n",
    "    replicates under each condition, and the set of genes will be extracted. \n",
    "    They will be returned as lists.\n",
    "    \n",
    "    direction: String. Path to the folder where all .JSON files are stored.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Read the expression .json files based on the direction path.\n",
    "    os.chdir(direction)\n",
    "    files = []\n",
    "    expr_files = []  # Full data for all conditions.\n",
    "\n",
    "    for file in glob.glob(\"*.json\"):\n",
    "        files.append(file)\n",
    "\n",
    "    for file in files:\n",
    "        f = open(file)\n",
    "        data = json.load(f)\n",
    "        expr_files.append(data)  \n",
    "        \n",
    "        \n",
    "    # Extract the conditions, expression data and replicates.\n",
    "    conditions = []\n",
    "    expression = []\n",
    "    replicates = []\n",
    "    for data in expr_files:\n",
    "        conditions.append(data[\"condition\"])\n",
    "        expression.append(data[\"expression\"])\n",
    "        replicates.append(data[\"replicates\"])\n",
    "        \n",
    "        \n",
    "    # Extract all appeared genes. And because under each condition, the \n",
    "    # number of genes is(should) be the same. Only take the gene name \n",
    "    # set from the first condition.\n",
    "    genes = list(expression[0].keys())\n",
    "    \n",
    "    return conditions, expression, replicates, genes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17606333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mov_data(direction):\n",
    "    \"\"\"\n",
    "    This function extracts the movement information, conditions, replicates,\n",
    "    and (GeneID, ProtID) from .JSON files containing movement results.\n",
    "    Movements are applied for calculations of final ewfd score.\n",
    "    Lists of conditions, mean_movement, and IDs will be returned.\n",
    "    \n",
    "    direction: String. Path to the folder where all .JSON files are stored.\n",
    "    \"\"\"\n",
    "    # Read in data (.json files).\n",
    "    os.chdir(direction)\n",
    "    files = []\n",
    "    mov_files = []\n",
    "    # Find all .json files along the direction.\n",
    "    for file in glob.glob(\"*.json\"):\n",
    "        files.append(file)\n",
    "    # Open all files and gather them together.\n",
    "    for c in files:\n",
    "        f = open(c)\n",
    "        data = json.load(f)\n",
    "        mov_files.append(data) \n",
    "        \n",
    "        \n",
    "    # Extract condition, id and mean_mov information for each replicate.\n",
    "    conditions = []\n",
    "    replicates = []\n",
    "    all_mean_mov = []\n",
    "    all_id = []\n",
    "    for data in mov_files:\n",
    "        conditions.append(data[\"condition\"])\n",
    "        replicates.append(data[\"replicates\"])\n",
    "        movement = data[\"movement\"]\n",
    "        merge_id = []\n",
    "        mean_mov = []\n",
    "        for gene in movement.keys():\n",
    "            protlist = movement[gene][\"prot_ids\"]\n",
    "            mean_movlist = movement[gene][\"mean_mov\"]\n",
    "            for i in range(len(protlist)):\n",
    "                merge_id.append((gene, protlist[i]))\n",
    "                mean_mov.append(mean_movlist[i])\n",
    "        all_mean_mov.append(mean_mov)\n",
    "        all_id.append(merge_id)\n",
    "        \n",
    "        \n",
    "    return conditions, replicates, all_mean_mov, all_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0d9a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_tool_expr(DataFrame, delete_column, replicates, conditions):\n",
    "    \"\"\"\n",
    "    This function applies PCA on the given DataFrame containing expression\n",
    "    data. The overall information content vector and principal components \n",
    "    for all replicates under all conditions will be returned.\n",
    "    \n",
    "    DataFrame: the DataFrame containing expression value.\n",
    "    delete_column: the index of column with GeneID or (GeneID, ProtID)\n",
    "    replicates: the list of replicates for each condition.\n",
    "    conditions: the list of involved conditions. \n",
    "    \n",
    "    \"\"\"\n",
    "    # Applying the PCA approach to generate the PC dataframe.\n",
    "    pca_DF = DataFrame.drop(columns = delete_column)\n",
    "    tdf = pca_DF.T\n",
    "    ids = tdf.columns\n",
    "    x = tdf.loc[:, ids].values\n",
    "    y = pd.DataFrame(tdf.index.values, columns = [\"repl\"])\n",
    "    targets = list(y[\"repl\"])\n",
    "    x = StandardScaler().fit_transform(x)\n",
    "    # Number of all replicates = number of DF columns - 1 because the first\n",
    "    # column is the ids. \n",
    "    n_repl = len(DataFrame.columns)-1\n",
    "    pca = PCA(n_components=n_repl)\n",
    "    column = []\n",
    "    for i in range(n_repl):\n",
    "        column.append(\"PC\"+str(i+1))\n",
    "    principalComponents = pca.fit_transform(x)\n",
    "    # Columns are the PCs and index replicates.\n",
    "    principalDf = pd.DataFrame(data = principalComponents\n",
    "                    , columns = column, index = y[\"repl\"])\n",
    "    \n",
    "    \n",
    "    # Iterativly add condition and its corresponded replicates with CP to\n",
    "    # a dictionary.\n",
    "    temp_pos = 0\n",
    "    cond_dict = {}\n",
    "    for i in range(len(conditions)):\n",
    "        repl_dict = {}\n",
    "        repl = principalDf.iloc[temp_pos:temp_pos+len(replicates[i])].\\\n",
    "                to_dict(\"index\")\n",
    "        repl_dict[\"replicates\"] = repl\n",
    "        cond_dict[conditions[i]] = repl_dict\n",
    "        temp_pos += len(replicates[i])\n",
    "        \n",
    "    \n",
    "    # Generate the dictionary for general information content.\n",
    "    info_content = pca.explained_variance_ratio_\n",
    "    info_contentDf = pd.DataFrame(data = info_content\n",
    "                                , columns = [\"information_content\"]\n",
    "                                , index = column).T\n",
    "    result_info = info_contentDf.to_dict(\"index\")[\"information_content\"]\n",
    "    \n",
    "    return result_info, cond_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2262e0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_tool_mov(DataFrame, delete_column, unique_cond, repl_num\n",
    "                , replicates):\n",
    "    \"\"\"\n",
    "    This function applies PCA on the given DataFrame containing \n",
    "    EWFD scores calculated from movements and generate \n",
    "    the overall information content and principal components for all \n",
    "    replicates and conditions. \n",
    "     \n",
    "    DataFrame: EWFD score DataFrame.\n",
    "    delete_column: The index of the coulumn with (GeneID, ProtID) \n",
    "    unique_cond: list of the involved conditions (without repeat)\n",
    "    repl_num: list of numbers of replicates for each condition.\n",
    "    replicates: list of replicates for each condition. \n",
    "    \n",
    "    \"\"\"\n",
    "    # Apply PCA approach on the EWFD data frame.\n",
    "    pca_DF = DataFrame.drop(columns = delete_column)\n",
    "    tdf = pca_DF.T\n",
    "    ids = tdf.columns\n",
    "    x = tdf.loc[:, ids].values\n",
    "    y = pd.DataFrame(tdf.index.values, columns = [\"repl\"])\n",
    "    targets = list(y[\"repl\"])\n",
    "    x = StandardScaler().fit_transform(x)\n",
    "\n",
    "    n_replicates = len(replicates)\n",
    "    pca = PCA(n_components=n_replicates)\n",
    "    column = []\n",
    "    for i in range(n_replicates):\n",
    "        column.append(\"PC\"+str(i+1))\n",
    "    principalComponents = pca.fit_transform(x)\n",
    "    # Columns are the PCs and index replicates.\n",
    "    principalDf = pd.DataFrame(data = principalComponents\n",
    "                    , columns = column, index = y[\"repl\"])\n",
    "    \n",
    "    # Information content of PCA approach. \n",
    "    info_content = pca.explained_variance_ratio_\n",
    "    info_contentDf = pd.DataFrame(data = info_content\n",
    "                            , columns = [\"information_content\"]\n",
    "                            , index = column).T\n",
    "    result_info = info_contentDf.to_dict(\"index\")[\"information_content\"]\n",
    "    \n",
    "    \n",
    "    # Iterativly match the condition and all its replicates with \n",
    "    # corresponded PCs from principalDf. \n",
    "    temp_pos = 0\n",
    "    cond_dict = {}\n",
    "    for i in range(len(unique_cond)):\n",
    "        repl_dict = {}\n",
    "        repl = principalDf.iloc[temp_pos:temp_pos+repl_num[i]].to_dict(\"index\")\n",
    "        repl_dict[\"replicates\"] = repl\n",
    "        cond_dict[unique_cond[i]] = repl_dict\n",
    "        temp_pos += repl_num[i]\n",
    "        \n",
    "    return result_info, cond_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f2eef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PC_gene_expr(direction):\n",
    "    \"\"\"\n",
    "    This function generates all principal components for all conditions\n",
    "    and all replicates from PCA of gene expression.\n",
    "    Also the overall information content vector is included.\n",
    "    A dictionary of the information will be returned.\n",
    "    \n",
    "    direction: String. Path to the folder of all expression files.\n",
    "    \"\"\"\n",
    "    # Read expression data.\n",
    "    expr_data = read_expression_data(direction)\n",
    "    \n",
    "    conditions = expr_data[0]\n",
    "    expression = expr_data[1]\n",
    "    replicates = expr_data[2]\n",
    "    genes = expr_data[3]\n",
    "    \n",
    "    DF = pd.DataFrame(genes, columns = [\"gene_id\"])\n",
    "    \n",
    "    # Extract the \"total\" gene expression over all replicates. Merge them\n",
    "    # together to form a general data frame (could be returned to view the\n",
    "    # original data). The index of the data frame are renamed replicates.\n",
    "    # The number n after the condition indicates the n-th replicate. \n",
    "    for i in range(len(conditions)):\n",
    "        expr = expression[i]\n",
    "        repl = replicates[i]\n",
    "        cond = conditions[i]\n",
    "        total_expr = np.zeros((len(genes),len(repl)))\n",
    "        for j in range(len(genes)):\n",
    "            gene = genes[j]\n",
    "            for k in range(len(repl)):\n",
    "                repl_name = repl[k]\n",
    "                total_expr[j, k] = expr[gene][repl_name][\"total\"]\n",
    "                \n",
    "            \n",
    "        temp_DF = pd.DataFrame(total_expr, columns = repl)\n",
    "        DF = pd.concat([DF, temp_DF], axis = 1)\n",
    "    \n",
    "    # Apply PCA and generate the dictionary. \n",
    "    results = PCA_tool_expr(DF, \"gene_id\", replicates, conditions)\n",
    "    result_info = results[0]\n",
    "    cond_dict = results[1]\n",
    "    \n",
    "    return {\"information_content\":result_info, \"conditions\":cond_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4658a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PC_transcript_expr(direction):\n",
    "    \"\"\"\n",
    "    This function generates all principal components for all conditions\n",
    "    and all replicates from PCA of transcript expression.\n",
    "    Also the overall information content vector is included.\n",
    "    A dictionary of the information will be returned.\n",
    "    \n",
    "    direction: String. Path to the folder of all expression files.\n",
    "    \"\"\"\n",
    "    # Read expression data. \n",
    "    expr_data = read_expression_data(direction)\n",
    "    \n",
    "    conditions = expr_data[0]\n",
    "    expression = expr_data[1]\n",
    "    replicates = expr_data[2]\n",
    "    genes = expr_data[3]\n",
    "    \n",
    "    # Extract all combinations (gene_id, prot_id). Because all .json files\n",
    "    # have(should have) the same number of combinations. Could only take\n",
    "    # the set of all combinations from data under the first condition. \n",
    "    all_combine = []\n",
    "    data_cond1 = expression[0]\n",
    "    repl = replicates[0][0]  # Replicates of the first condition.\n",
    "    for i in range(len(genes)):\n",
    "        gene = genes[i]\n",
    "        keys = list(data_cond1[gene][repl].keys())\n",
    "        for prot in keys[1:]:  # In every key list, the first element is \"total\"\n",
    "            all_combine.append((gene, prot))\n",
    "    \n",
    "    DF_prot = pd.DataFrame(list(zip(all_combine)), columns = [\"gene_id,prot_id\"])\n",
    "    \n",
    "    # Extract all expression values for all combinations (gene_id, prot_id)\n",
    "    # for all conditions. And build up a data frame storing all expression\n",
    "    # for each (gene_id, prot_id) under every condition.\n",
    "    for i in range(len(conditions)):\n",
    "        expr = expression[i]\n",
    "        repl = replicates[i]\n",
    "        cond = conditions[i]\n",
    "        all_prot_expr = np.zeros((len(all_combine), len(repl)))\n",
    "        for j in range(len(all_combine)):\n",
    "            comb = all_combine[j]\n",
    "            gene_id = comb[0]\n",
    "            prot_id = comb[1]\n",
    "            for k in range(len(repl)):\n",
    "                repl_name = repl[k]\n",
    "                all_prot_expr[j,k] = expr[gene_id][repl_name][prot_id]\n",
    "        # Iterativly fulfill the data frame.\n",
    "        temp_DF = pd.DataFrame(all_prot_expr, columns = repl)\n",
    "        DF_prot = pd.concat([DF_prot, temp_DF], axis = 1)\n",
    "    \n",
    "    # Apply PCA and generate the dictionary. \n",
    "    results = PCA_tool_expr(DF_prot, \"gene_id,prot_id\", replicates, conditions)\n",
    "    result_info = results[0]\n",
    "    cond_dict = results[1]\n",
    "    \n",
    "    return {\"information_content\":result_info, \"conditions\":cond_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59f59cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PC_rel_transcript_expr(direction):\n",
    "    \"\"\"\n",
    "    This function generates all principal components for all conditions\n",
    "    and all replicates from PCA of relative transcript expression.\n",
    "    Also the overall information content vector is included.\n",
    "    A dictionary of the information will be returned.\n",
    "    \n",
    "    direction: String. Path to the folder of all expression files. \n",
    "    \"\"\"\n",
    "    # Read expression data. \n",
    "    expr_data = read_expression_data(direction)\n",
    "    \n",
    "    conditions = expr_data[0]\n",
    "    expression = expr_data[1]\n",
    "    replicates = expr_data[2]\n",
    "    genes = expr_data[3]\n",
    "    \n",
    "    # Extract all combinations (gene_id, prot_id). Because all .json files\n",
    "    # have(should have) the same number of combinations. Could only take\n",
    "    # the set of all combinations from data under the first condition. \n",
    "    all_combine = []\n",
    "    data_cond1 = expression[0]\n",
    "    repl = replicates[0][0]  # Replicates of the first condition.\n",
    "    for i in range(len(genes)):\n",
    "        gene = genes[i]\n",
    "        keys = list(data_cond1[gene][repl].keys())\n",
    "        for prot in keys[1:]:  # In every key list, the first element is \"total\"\n",
    "            all_combine.append((gene, prot))\n",
    "            \n",
    "    # Build up iterativly the data frame containing all relativ splice \n",
    "    # expression under each condition. \n",
    "    DF_rel_prot1 = pd.DataFrame(list(zip(all_combine)), \n",
    "                                columns = [\"gene_id,prot_id\"])\n",
    "    \n",
    "    for i in range(len(conditions)):\n",
    "        expr = expression[i]\n",
    "        repl = replicates[i]\n",
    "        cond = conditions[i]\n",
    "        all_prot_expr = np.zeros((len(all_combine), len(repl)))\n",
    "        for j in range(len(all_combine)):\n",
    "            comb = all_combine[j]\n",
    "            gene_id = comb[0]\n",
    "            prot_id = comb[1]\n",
    "            for k in range(len(repl)):\n",
    "                repl_name = repl[k]\n",
    "                single_gene_expr = expr[gene_id][repl_name][\"total\"]\n",
    "                if single_gene_expr != 0:\n",
    "                    # Calculation relative expression. \n",
    "                    all_prot_expr[j,k] = expr[gene_id][repl_name][prot_id]/single_gene_expr\n",
    "                # else: if the single gene is not expressed, then the isoforms\n",
    "                # are also not expressed. In this case, the \"score\" will be 0\n",
    "\n",
    "        temp_DF = pd.DataFrame(all_prot_expr, columns = repl)\n",
    "        DF_rel_prot1 = pd.concat([DF_rel_prot1, temp_DF], axis = 1)\n",
    "    \n",
    "    # Apply PCA.\n",
    "    results = PCA_tool_expr(DF_rel_prot1, \"gene_id,prot_id\", replicates, conditions)\n",
    "    result_info = results[0]\n",
    "    cond_dict = results[1]\n",
    "    \n",
    "    return {\"information_content\":result_info, \"conditions\":cond_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "120c72c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PC_EWFD(direction):\n",
    "    \"\"\"\n",
    "    This function generates all principal components for all conditions\n",
    "    and all replicates from PCA of EWFD scores.\n",
    "    Also the overall information content vector is included.\n",
    "    A dictionary of the information will be returned.\n",
    "    \n",
    "    direction: String. Path to the folder of all movement files. \n",
    "    \"\"\"\n",
    "    # Read movement data.\n",
    "    mov_data = read_mov_data(direction)\n",
    "    \n",
    "    conditions =  mov_data[0]\n",
    "    replicates = mov_data[1]\n",
    "    all_mean_mov = mov_data[2]\n",
    "    all_id = mov_data[3]\n",
    "    \n",
    "    # Get all unique conditions and the number of replicates each condition\n",
    "    # has.\n",
    "    repl_num_dict = {i:conditions.count(i) for i in conditions}\n",
    "    # All unique conditions.\n",
    "    unique_cond = list(repl_num_dict.keys())\n",
    "    # The number of replicates for each condition from above list.\n",
    "    repl_num = list(repl_num_dict.values())\n",
    "    \n",
    "    \n",
    "    # Prepare the dataframe for PCA approach.\n",
    "    EWFD_table = pd.DataFrame(list(zip(all_id[0], 1-np.asarray(all_mean_mov[0]))),\\\n",
    "                        columns = [\"gene_id,prot_id\", replicates[0]])\n",
    "    for i in range(1,len(replicates)):\n",
    "        EWFD_table[replicates[i]] = 1-np.asarray(all_mean_mov[i])\n",
    "        \n",
    "    # Apply PCA. \n",
    "    results = PCA_tool_mov(EWFD_table, \"gene_id,prot_id\", unique_cond, repl_num\n",
    "                          , replicates)\n",
    "    result_info = results[0]\n",
    "    cond_dict = results[1]\n",
    "    \n",
    "    return {\"information_content\":result_info, \"conditions\":cond_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b098949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_JSON(expr_direction, mov_direction, writepath):\n",
    "    \"\"\"\n",
    "    This function generate a .JSON file containing all principal components\n",
    "    and information content for all four analysis levels.\n",
    "    \n",
    "    expr_direction: String. The path to the folder with all expression files.\n",
    "    mov_direction: String. The path to the folder with all movement files.\n",
    "    writepath: String. The path where the .JSON file should be generated. It\n",
    "    has the format of \"folder/name.json\".\n",
    "    \"\"\"\n",
    "    Data = {\"gene_expr_PCA\":PC_gene_expr(expr_direction),\\\n",
    "            \"transcript_expr_PCA\":PC_transcript_expr(expr_direction),\\\n",
    "            \"relative_transcript_expr_PCA\":PC_rel_transcript_expr(expr_direction),\\\n",
    "            \"EWDF_PCA\": PC_EWFD(mov_direction)}\n",
    "    pca_pc = json.dumps(Data, indent=4)  \n",
    "    mode = 'a' if os.path.exists(writepath) else 'w'\n",
    "    with open(writepath, mode) as f:\n",
    "        f.write(pca_pc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
